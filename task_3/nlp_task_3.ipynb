{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1.TF-IDF原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"微软雅黑\" size=4>\n",
    "    TF-IDF 是 Term Frequency - Inverse Document Frequency 的缩写，词频-逆文本。TF反应词在文本中出现的频率，IDF反应一个词在所有文本中出现的频率。\n",
    "$$IDF(x)=log\\frac{N}{N(x)}$$\n",
    "    其中，$N$代表语料库中文本的总数，$N(x)$代表语料库中包含词$x$的文本总数，对公式进行平滑：\n",
    "$$IDF(x)=log\\frac{N+1}{N(x)+1}+1$$\n",
    "    tf-idf计算公式为：\n",
    "    $$TF-IDF=TF(x)\\times IDF(x)$$\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个词在每个文本里对应的频数:\n",
      "  (0, 3)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t2\n",
      "  (0, 15)\t2\n",
      "  (0, 28)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 25)\t2\n",
      "  (0, 7)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 27)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 24)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 14)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 17)\t1\n",
      "  (3, 20)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 21)\t1\n",
      "  (3, 30)\t1\n",
      "  (3, 29)\t1\n",
      "  (3, 23)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 25)\t1\n",
      "=================\n",
      "显示每个词的tf-idf值: \n",
      "  (0, 7)\t0.2323987345417178\n",
      "  (0, 25)\t0.3664516633475799\n",
      "  (0, 6)\t0.18322583167378995\n",
      "  (0, 26)\t0.2323987345417178\n",
      "  (0, 28)\t0.2323987345417178\n",
      "  (0, 15)\t0.4647974690834356\n",
      "  (0, 10)\t0.4647974690834356\n",
      "  (0, 9)\t0.2323987345417178\n",
      "  (0, 4)\t0.2323987345417178\n",
      "  (0, 8)\t0.2323987345417178\n",
      "  (0, 13)\t0.1483371018604668\n",
      "  (0, 3)\t0.2323987345417178\n",
      "  (1, 6)\t0.28503967675464414\n",
      "  (1, 13)\t0.23076418416976147\n",
      "  (1, 24)\t0.361536687086221\n",
      "  (1, 5)\t0.361536687086221\n",
      "  (1, 19)\t0.361536687086221\n",
      "  (1, 12)\t0.28503967675464414\n",
      "  (1, 27)\t0.361536687086221\n",
      "  (1, 16)\t0.361536687086221\n",
      "  (1, 11)\t0.361536687086221\n",
      "  (2, 14)\t0.5\n",
      "  (2, 22)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (2, 2)\t0.5\n",
      "  (3, 25)\t0.2537908042237523\n",
      "  (3, 13)\t0.20546552870565463\n",
      "  (3, 12)\t0.2537908042237523\n",
      "  (3, 23)\t0.32190145462094216\n",
      "  (3, 29)\t0.32190145462094216\n",
      "  (3, 30)\t0.32190145462094216\n",
      "  (3, 21)\t0.32190145462094216\n",
      "  (3, 18)\t0.32190145462094216\n",
      "  (3, 20)\t0.32190145462094216\n",
      "  (3, 17)\t0.32190145462094216\n",
      "  (3, 0)\t0.32190145462094216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "corpus=[\"I come to China to travel with my gril friend but my gril freind is a boy\", \n",
    "    \"This is a car polupar in China which named hongqi\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science or acta\"] \n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "v = vectorizer.fit_transform(corpus)#每个词在每个文本里对应的频数\n",
    "print(\"每个词在每个文本里对应的频数:\")\n",
    "print(v)\n",
    "print(\"=================\")\n",
    "print(\"显示每个词的tf-idf值: \")\n",
    "tfidf = transformer.fit_transform(v)#.toarray()  #显示每个词的tf-idf值 \n",
    "print (tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.文本矩阵化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$j$个文本里的$i$个去重单词，构成矩阵，列数为单词个数，行数为文本个数，每个值$x_{ij}$对应每个单词的tf-idf值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.23239873 0.23239873 0.\n",
      "  0.18322583 0.23239873 0.23239873 0.23239873 0.46479747 0.\n",
      "  0.         0.1483371  0.         0.46479747 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.36645166 0.23239873 0.         0.23239873 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.36153669\n",
      "  0.28503968 0.         0.         0.         0.         0.36153669\n",
      "  0.28503968 0.23076418 0.         0.         0.36153669 0.\n",
      "  0.         0.36153669 0.         0.         0.         0.\n",
      "  0.36153669 0.         0.         0.36153669 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.5        0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.32190145 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2537908  0.20546553 0.         0.         0.         0.32190145\n",
      "  0.32190145 0.         0.32190145 0.32190145 0.         0.32190145\n",
      "  0.         0.2537908  0.         0.         0.         0.32190145\n",
      "  0.32190145]]\n",
      "===============\n",
      "文本数： 4 单词数： 31\n"
     ]
    }
   ],
   "source": [
    "arraytfidf = tfidf.toarray()\n",
    "print(arraytfidf)\n",
    "print(\"===============\")\n",
    "print(\"文本数：\",len(arraytfidf),\"单词数：\",len(arraytfidf[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.互信息的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "互信息是信息论里的一种信息度量，它可以看成是一个随机变量中包含的关于另一个随机变量的信息量，或者说是一个随机变量由于已知另一个随机变量二减少的不确定性。\n",
    "设两个随机变量$(X,Y)$的联合概率分布为$p(x,y)$,边缘概率分布为$p(x),p(y)$,互信息$I(X;Y)$是联合分布$p(x,y)$于乘积分布$p(x),p(y)$的相对熵\n",
    "$$I(X;Y)=\\sum_{x\\subset X,y\\subset Y}p(x,y)log\\frac{p(x,y)}{p(x)p(y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics as mr\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "每个单词作为特征：\n",
      "['acta' 'and' 'apple' 'boy' 'but' 'car' 'china' 'come' 'freind' 'friend'\n",
      " 'gril' 'hongqi' 'in' 'is' 'love' 'my' 'named' 'or' 'papers' 'polupar'\n",
      " 'science' 'some' 'tea' 'the' 'this' 'to' 'travel' 'which' 'with' 'work'\n",
      " 'write']\n"
     ]
    }
   ],
   "source": [
    "eachwords = vectorizer.get_feature_names()\n",
    "eachwords = np.asarray(eachwords)\n",
    "eachwords = eachwords.T\n",
    "print(type(eachwords))\n",
    "print(\"每个单词作为特征：\")\n",
    "print(eachwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个单词和后三个单词之间的互信息：\n",
      "0.3528681999138815\n",
      "0.0691103344933365\n",
      "0.3946507687941262\n"
     ]
    }
   ],
   "source": [
    "#arraytfidf = arraytfidf.T\n",
    "#mutual_info = mutual_info_classif(arraytfidf, eachwords, discrete_features= False)\n",
    "#print(np.mat(arraytfidf))\n",
    "print(\"第一个单词和后三个单词之间的互信息：\")\n",
    "print(mr.mutual_info_score(arraytfidf[0], arraytfidf[1]))\n",
    "print(mr.mutual_info_score(arraytfidf[0], arraytfidf[2]))\n",
    "print(mr.mutual_info_score(arraytfidf[0], arraytfidf[3]))\n",
    "#mr.mutual_info_score(arraytfidf,eachwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
